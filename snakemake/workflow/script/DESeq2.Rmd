---
title: "DE Analysis and Standard Visualizations"
output:
  html_document:
    toc: yes
    code_folding: hide
    toc_float: yes
params: 
  max_fdr: 0.05
  min_lfc: 0.585
  indfilter: FALSE
  cookscutoff: TRUE
  countFile: '../example_data/counts/featureCounts.mm10.txt' # all three formats need to be tested in development
  annoFile: 'https://raw.githubusercontent.com/radio1988/OneStopRNAseq/master/snakemake/envs/anno_tables/mm10.gencode.vm25.te_included.anno.txt'
  #annoFile: 'https://raw.githubusercontent.com/radio1988/OneStopRNAseq/master/snakemake/envs/anno_tables/hg38.gencode.v34.te_included.anno.txt'
  metaFile: "../meta/meta.xlsx"
  contrastFile:  "../meta/contrast.de.xlsx"
---

## Notes:
- Please search for “Warning” in this report for possible problems before proceeding
-	Normalized expression values, differentially expressed genes, and various types of plots such as heatmap and volcano plots are in the DESeq2 folder. For example, TPM.xlsx contains normalized expression values.
- Please use LFC_shrunken for Log2FoldChange, LFC_raw is not recommended
- Please use FDR (padj) instead of raw p-values for identifying significantly differentially expressed genes.

```{r setup, include=F}
# Bioconductor
library(BiocManager) # 
library(DESeq2)
library(EnhancedVolcano) # hard to install via conda

# CRAN
library(ggrepel) # 
library(ggplot2)
library(ashr) # 
library(MASS)
library(WriteXLS)
library(plyr) # 
library(gdata) #
library(dplyr)
library(RColorBrewer)
library(pheatmap) #
library(PoiClaClu) # 
library(gridExtra) # 
library(grid)
# library(corrplot) 

dir.create("../../DESeq2", showWarnings = FALSE)
dir.create("../../DESeq2/rnk", showWarnings = FALSE)
knitr::opts_knit$set(root.dir = "../../DESeq2")
```


## Input parameter extraction
```{r params}
max_fdr <- params$max_fdr
min_lfc <- params$min_lfc
indfilter <- params$indfilter
cookscutoff <- params$cookscutoff

countFile <- params$countFile
annoFile <- params$annoFile
metaFile <- params$metaFile
contrastFile <-params$contrastFile

paste("Data file name:", countFile)
paste("MetaData file name:", metaFile)
paste("Contrast file name:", contrastFile)
paste("Annotation file name:", annoFile)
paste("FDR cut-off:", max_fdr)
paste("Log2FC cut-off:", min_lfc)
```

## Functions
```{r functions}
readExcel <- function(fname){
  df <- readxl::read_xlsx( fname, na='NA', sheet=1)  # na term important
  df <- data.frame(df)  #important
  return (df)
}

get_density <- function(x, y, ...) {
  dens <- MASS::kde2d(x, y, ...)
  ix <- findInterval(x, dens$x)
  iy <- findInterval(y, dens$y)
  ii <- cbind(ix, iy)
  return(dens$z[ii])
}


volcanoplot <- function(res, anno, name='name', 
                        lfcthresh=2, sigthresh=0.05, 
                        labelsig=FALSE, xlim=100, ylim=1000, textcx=1) {
  # If Annotation file is wrong, No annotation match
  res0 <- res
  res<-merge(data.frame(res0), anno, by.x = 0, by.y=1, all.x=T, sort=F)
  if (sum(anno[, 1] %in% row.names(res0)) < 1) {
    warning(
      c("\nThe annotation file and the count filt does have no match in gene-id:\n", 
        "count table gene-id: ", head(row.names(res0), 1), 
        "\nanno table gene-id: ", anno[1:1, 1], 
        "gene-id rather than gene-name used for Volcano-plot"
      ))
    res$Name <- res[, 1]
  }
  
  # remove NA
  res$padj[is.na(res$padj)] <- 1
  # set lim on x, y
  res$padj[res$padj < 10^(-ylim) & !is.na(res$padj)] <- 10^(-ylim) # y-axis top value 50
  res$log2FoldChange[res$log2FoldChange > xlim] <- xlim
  res$log2FoldChange[res$log2FoldChange < -xlim] <- -xlim
  # show num_pos num_neg
  pos <- subset(res, padj<sigthresh & log2FoldChange>lfcthresh)
  neg <- subset(res, padj<sigthresh & log2FoldChange< -lfcthresh)
  pos.n <- dim(pos)[1]
  neg.n <- dim(neg)[1]
  
  #labelcut <- res$padj[order(res$padj)][100] 
  
  p <- EnhancedVolcano(res,
                       lab = res$Name,
                       #selectLab = as.character(res$Name[which(res$padj<labelcut)]), # mark top genes
                       #selectLab = c("FOS", "LDHA"), # mark selected genes
                       x = 'log2FoldChange',
                       y = 'padj',
                       title = name,
                       subtitle = paste("Up:", pos.n, ", Down:", neg.n, sep = ""),
                       xlab = bquote(~Log[2]~ "Fold Change"),
                       ylab = bquote(~-Log[10]~italic(FDR)),
                       #xlim = c(-6, 6),
                       pCutoff = sigthresh,
                       FCcutoff = lfcthresh,
                       #pLabellingCutoff = labelcut,
                       cutoffLineType = 'twodash',
                       cutoffLineWidth = 0.8,
                       # pointSize = 1.0, # todo: fix incomparibility in R3.5 and R4
                       # labSize = 2.0,
                       # DrawConnectors = F,
                       # legend = c("NS","Log2 FC","P","P & Log2 FC"),
                       legendLabels = c('NS', expression(Log[2]~FC),
                                        "FDR", expression(FDR~and~Log[2]~FC)),
                       caption = paste0('Total = ', nrow(res), ' genes'),
                       legendPosition = 'right',
                       legendLabSize = 10,
                       axisLabSize = 10,
                       legendIconSize = 3.0)
  
  # # plot in html
  # grid.arrange(p,
  #              ncol=1,
  #              top = textGrob(' ',
  #                             just = c('center'),
  #                             gp = gpar(fontsize = 32))
  # )
  # grid.rect(gp=gpar(fill=NA))
  
  # save PDF
  pdf(paste(name, "pdf", sep="."), width=8, height=6)
  grid.arrange(p,
               ncol=1,
               top = textGrob(' ',
                              just = c('center'),
                              gp = gpar(fontsize = 32))
  )
  grid.rect(gp=gpar(fill=NA))
  dev.off()
}


maplot <- function (res, thresh=max_fdr, labelsig=FALSE, textcx=1, ...) {
  # todo: improve visualization
  with(res, 
       plot(baseMean, log2FoldChange, col="grey80", pch=20, cex=.5, log="x", ...))
  with(subset(res, padj<max_fdr), 
       points(baseMean, log2FoldChange, col="grey40", pch=20, cex=.5))
  if (labelsig) {
    require(calibrate)
    with(subset(res, padj<max_fdr), 
         textxy(baseMean, log2FoldChange, labs=Gene, cex=textcx, col=2))
  }
}

zscore <- function(matrix){
  return( t(scale(t(matrix))))
}

rename_num_vector_by_order <- function(l){
  # l have to be a vector of numbers
  # output vector of roman numbers ordered by appearance in the input vector
  # e.g. c(2,3,3,2,1) -> c(I, II, II, I, III)
  # test rename_num_vector_by_order(c(2,3,3,2,1))
  u <- unique(l)
  n=0
  for (i in u){
    n = n+1; 
    l <- replace(l, l==i, as.character(as.roman(n)))
  }
  return(l)
}

Heatmap <- function(df, nclass=2, fname="heatmap", main="title"){
  if (dim(df)[1] > nclass){
    # Heatmap Pre-plot to get hclust
    p <- pheatmap(df, 
                  main = main,
                  cluster_cols = F, 
                  border_color = NA,
                  cutree_rows = nclass, 
                  show_rownames = F)

    ## Print out gene classification (https://www.biostars.org/p/287512/)
    # cutree manually
    gene_classes <- sort(cutree(p$tree_row, k=nclass))
    gene_classes <- data.frame(gene_classes) 
    classification <- merge(gene_classes, df, by = 0)
    row.names(classification) <- classification$Row.names
    # Re-order original data (genes) to match ordering in heatmap (top-to-bottom)
    idx <- rownames(df[p$tree_row[["order"]],])
    classification <- classification[idx,] 
    # rename gene classes
    classification$gene_classes <- rename_num_vector_by_order(classification$gene_classes)
    # save excel
    WriteXLS(classification, row.names = F,
             paste(fname,"gene_class.xlsx", sep = "."))
    # get class label
    annotation_row = data.frame(
      class = classification$gene_classes
    )
    row.names(annotation_row) <- row.names(classification)
    annotation_row$class <- as.character(annotation_row$class)
    # output final plot
    if (dim(df)[1] < 20){ # manage row height
        p2 <- pheatmap(df,
           main = main,
           border_color = NA,
           cluster_cols = F,
           cutree_rows = nclass,
           show_rownames = F,
           annotation_row = annotation_row,
           cellheight = 20,
           filename = paste(fname, "pdf", sep = "."))
        p3 <- pheatmap(df,  # sample clustering
           main = main,
           border_color = NA,
           cluster_cols = T,
           cutree_rows = nclass,
           show_rownames = F,
           annotation_row = annotation_row,
           cellheight = 20,
           filename = paste(fname, "v2.pdf", sep = "."))
    }else{
        p2 <- pheatmap(df,
           main = main,
           border_color = NA,
           cluster_cols = F,
           cutree_rows = nclass,
           show_rownames = F,
           annotation_row = annotation_row,
           filename = paste(fname, "pdf", sep = "."))
        p3 <- pheatmap(df, # sample clustering
           main = main,
           border_color = NA,
           cluster_cols = T,
           cutree_rows = nclass,
           show_rownames = F,
           annotation_row = annotation_row,
           filename = paste(fname, "v2.pdf", sep = "."))
    }

  }else if (dim(df)[1] > 0){
    # output final plot
        if (dim(df)[1] < 20){ # manage row height
            p2 <- pheatmap(df,
               main = main,
               cluster_cols = F,
               cluster_rows = F,
               border_color = NA,
               show_rownames = F,
               cellheight = 20,
               filename = paste(fname, "pdf", sep = "."))
            p3 <- pheatmap(df,
               main = main,
               cluster_cols = T,
               cluster_rows = F,
               border_color = NA,
               show_rownames = F,
               cellheight = 20,
               filename = paste(fname, "v2.pdf", sep = "."))
        }else{
            p2 <- pheatmap(df,
               main = main,
               cluster_cols = F,
               cluster_rows = F,
               border_color = NA,
               show_rownames = F,
               filename = paste(fname, "pdf", sep = "."))
            p3 <- pheatmap(df,
               main = main,
               cluster_cols = T,
               cluster_rows = F,
               border_color = NA,
               show_rownames = F,
               filename = paste(fname, "v2.pdf", sep = "."))
        }
  }else{ print("no sig DEG for heatmap")}
}


process_deseq_res <- function(res="lfcshrink.res", res2="results.res", name='name', anno='anno.df', norm_exp="tpm.df"){
    ## Summary
    print(name)
    print("\n>>> Summary using FDR cut-off only (LFC not used)")
    summary(res, alpha=max_fdr)
    
    print("\n>>> Summary using both FDR and LFC_shrunken cut-off")
    sig_idx <- res$padj<max_fdr & abs(res$log2FoldChange) > min_lfc
    sig_idx[is.na(sig_idx)] <- FALSE
    res_sig <- res[sig_idx,]
    print(table(sig_idx))
    
    up_idx <- res$padj<max_fdr & res$log2FoldChange > min_lfc
    up_idx[is.na(up_idx)] <- FALSE
    res_sig <- res[up_idx,]
    print(table(up_idx))
    
    down_idx <- res$padj<max_fdr & res$log2FoldChange < -min_lfc
    down_idx[is.na(down_idx)] <- FALSE
    res_sig <- res[down_idx,]
    print(table(down_idx))

    # Prep
    res.df <- as.data.frame(res)
    names(res.df)[2] <- "log2FoldChange_shrunken"
    names(res.df)[3] <- "lfcSE_shrunken"

    res2.df <- as.data.frame(res2)
    names(res2.df)[2] <- "log2FoldChange_raw"
    names(res2.df)[3] <- "lfcSE_raw"
    res2.df <- res2.df[, c(2,3)]

    resdata <- merge(res.df, res2.df, by=0, sort=F, all.x=T)
    resdata <- merge(anno, resdata, by.x=1, by.y=1, sort=F, all.y=T)
    resdata <- merge(resdata, norm_exp, by.x=1, by.y=0, all.x=T, sort=F)
    head(resdata)
    sig_idx <- resdata$padj<max_fdr & abs(resdata$log2FoldChange_shrunken) > min_lfc # important to put this line right before output sig.xlsx
    sig_idx[is.na(sig_idx)] <- FALSE
    resdata.sig <- resdata[sig_idx,]
    head(resdata.sig)

    ## Write results
    WriteXLS(x = resdata,
             ExcelFileName = paste(name, 'deseq2.xlsx', sep = '.'),
             row.names = F, SheetNames = 'sheet1', na = 'NA')  # for user

    WriteXLS(x = resdata.sig,
             ExcelFileName = paste(name, 'deseq2.sig.FDR', max_fdr,
                                   'LFC', min_lfc, 'xlsx', sep = '.'),
             row.names = F, SheetNames = 'sheet1', na = 'NA')  # for user
    ## For GSEA
    rnk <- subset(resdata, select = c("Name","log2FoldChange_shrunken"))
    colnames(rnk) <- c("# Name","log2FoldChange_shrunken")
    rnk <- rnk[order(rnk$log2FoldChange_shrunken), ]
    rnk[, 1] <- toupper(rnk[, 1])
    write.table(rnk, 
                paste('rnk/', name, '.rnk', sep = ''), 
                row.names = F, quote = F, sep='\t')


    # # Corrlelation of Length and LFC for Niraj (only after write excel, alters resdata)
    # resdata.sig.cor <- cor.test(resdata.sig$Length, 
    #                        resdata.sig$log2FoldChange_shrunken, 
    #                        method = "spearman")
    # title <- paste("Spearman Cor:", format(resdata.sig.cor$estimate, digits=2, nsmall=2),
    #                "p-value:", format(resdata.sig.cor$p.value, digits=3, nsmall=3),
    #                sep = " ")
    # 
    # resdata.sig$density <- get_density(resdata.sig$Length, resdata.sig$log2FoldChange_shrunken, n = 100)
    # # set lim (careful, only after outputting excel)
    # resdata.sig$log2FoldChange_shrunken[resdata.sig$log2FoldChange_shrunken > 10] <- 10
    # resdata.sig$log2FoldChange_shrunken[resdata.sig$log2FoldChange_shrunken < -10] <- -10
    # resdata.sig$Length[resdata.sig$Length > 20000] <- 20000
    # ggplot(resdata.sig) + 
    #     geom_point(aes(Length, log2FoldChange_shrunken, color = density)) +
    #     scale_color_viridis() +
    #     ggtitle(paste(paste("Sig-DEG for", name), title, sep = "\n") ) + 
    #     ylim(-10, 10) +        
    #     xlim(0,20000)
    
    ##  Plots
    hist(res$pvalue, breaks=50, col="grey80", # todo: improve vis
         main = paste('Histogram of p-values', name, sep = "\n"), 
         xlab = 'pvalues', ylab = 'Frequency')
    
    hist(res$padj, breaks=50, col="grey", 
         main = paste('Histogram of FDR', name, sep = "\n"), 
         xlab = 'FDR', ylab = 'Frequency')
    
    maplot(res, main=paste("MAplot", paste(name, "LFC_shrunken"), sep="\n")) # todo: improve vis
    maplot(res2, main=paste("MAplot", paste(name, "LFC_raw"), sep="\n"))
    
    volcanoplot(res, anno, lfcthresh=min_lfc, sigthresh=max_fdr,
                textcx=.8,  name= paste(name, "LFC_shrunken", sep="."))
    volcanoplot(res2, anno, lfcthresh=min_lfc, sigthresh=max_fdr,
                textcx=.8,name= paste(name, "LFC_raw", sep="."))
    
    n1 <- dim(resdata.sig)[2]
    n2 <- dim(norm_exp)[2]
    zscore.df <- zscore(resdata.sig[, (n1-n2+1):n1])
    rownames(zscore.df) <- resdata.sig[,1]
    colnames(zscore.df) <- gsub (":TPM", "", colnames(zscore.df))
    Heatmap(zscore.df, nclass = 2,
            fname = paste(name, "heatmap", sep="."),
            main = paste(name, "LFC >", min_lfc, "FDR <", max_fdr ))
    # dev.off()


}
```


## Importing data
```{r read_meta_data}
meta.df <- readExcel(metaFile)
```

```{r read_count_data}
# read
if (grepl("txt$", countFile)){
  df <- read.table(countFile, 
                   sep="\t", header=TRUE, comment.char = '#', 
                   row.names = 1) # row.name in cts(matrix)
} else if (grepl("xlsx$", countFile)){
  df <- readExcel(countFile)  
} else {
  stop("input count file not xlsx, nor txt format, abort!!!")
}

# auto-detect content format
featureCountsFormat <- F
cleanCountFormat <- F
osrCountFormat <- F

if (colnames(df)[1] == "Chr" & colnames(df)[2] == "Start" & colnames(df)[3] == "End"){
  cat("featureCounts format table detected\n")
  featureCountsFormat <- T
  # clean names
  colnames(df) <- gsub("\\.bam$", "", colnames(df))
  colnames(df) <- gsub("sorted_reads.", "", colnames(df))
  colnames(df) <- gsub("mapped_reads.", "", colnames(df))
  # convert to int
  df[, 6:ncol(df)] <- sapply(df[, 6:ncol(df)], as.integer)
  # get cts
  cts <- as.matrix(df[, 6:ncol(df)])
} else if (dim(df)[2] == dim(meta.df)[1] + 1){
  cat("clean format table detected\n")
  cleanCountFormat<- T
  row.names(df) <- df[, 1]
  df[, 2:ncol(df)] <- sapply(df[, 2:ncol(df)], as.integer)
  cts <- as.matrix(df[, 2:ncol(df)])
} else if (colnames(df)[1] == "Gene" & colnames(df)[2] == "Name" & colnames(df)[3] == "Type") {
  cat("OSR COUNT.xlsx format detected\n")
  osrCountFormat <- T
  # clean names
  colnames(df) <- gsub(".COUNT", "", colnames(df))
  # convert to int
  df[, 4:ncol(df)] <- sapply(df[, 4:ncol(df)], as.integer)
  row.names(df) <- df$Gene
  # get cts
  cts <- as.matrix(df[, 4:ncol(df)])
} else {
  stop("COUNT file not in featureCounts output format, nor cleanCountFormat format, nor osrCount format. \nMay have different number of samples in meta-data and count-table if cleanCountFormat is provided\n")
}

# check number of samples
if ( dim(cts)[2] != dim(meta.df)[1] ){
  paste("# samples in count-table:", dim(cts)[2] )
  paste("# samples in meta-data provided:", dim(meta.df)[1] )
  stop("the number of samples in count-table does not match the number of samples in meta-data")
}

# check sample names
if (all(colnames(cts) %in% meta.df$SAMPLE_LABEL) & all(meta.df$SAMPLE_LABEL %in% colnames(cts)) ){
  cat("all sample-labels in count-table and meta-data matches")
} else {
  warning("count-table: ", colnames(cts), "\n")
  warning("meta-data: ", meta.df$SAMPLE_LABEL, "\n")
  stop("not all sample-labels in count-table and meta-data matches, abort!!!")
}



# Report Summary
print(paste("lib-size in millions:"))
print(format(colSums(cts/1e6), digits=2))
print(paste("Dim of input data:"))
print(dim(cts))
```


## Importing annotation
```{r import_annotation}
# from GitHub (must be raw, not zipped)
getAnnotation <- function(urlpath) {
  tmp <- tempfile()
  download.file(urlpath, destfile = tmp, method = 'auto')
  return(read.table(tmp, sep="\t", header = TRUE))
}

paste("Getting data from", annoFile)

if (grepl('https://', annoFile)){
  print("downloading remote annoFile")
  anno <- getAnnotation(annoFile)
}else{
  print("reading local annoFile")
  anno <- read.table(annoFile, sep = "\t", header = T)
}
print("Dimention of annotation table: ")
dim(anno)
head(anno)

if (sum(anno[, 1] %in% row.names(cts)) < 1){
  warning("!!! Annotation file and count file have no ID in common")
  warning("The results will be unannotated")
  warning("Please Double check Annotation file")
  print("count table ID:")
  print(row.names(cts)[1:2])
  print("anno table ID:")
  print(anno[1:2, 1])
  }
```

## COUNT output (without filtering)
```{r}
count <- data.frame(cts)
colnames(count) <- paste(colnames(count),"COUNT", sep = ":")
count_out <- merge(anno, count, by.x=1, by.y=0, all.y=T, sort=F)
head(count_out)
WriteXLS(x = count_out, 
         ExcelFileName = 'COUNT.xlsx', row.names = F, SheetNames = 'sheet1', na = 'NA')
print("saved in COUNT.xlsx")
```

## Filtering
```{r filtering}
min_rowsum <- 10
expression_filter <- rowSums(cts) >= min_rowsum  # default 10
min_colsum <- 2e4
sample_filter <- colSums(cts) >= min_colsum
if (sum(expression_filter) > 2 & sum(sample_filter) >= 4){
  cts <- cts[expression_filter, sample_filter]
  if (featureCountsFormat) {
    df <- df[expression_filter, c(rep(TRUE,5), sample_filter )]
  }else if (cleanCountFormat) {
    df <- df[expression_filter, sample_filter]
  } else if (osrCountFormat) {
    df <- df[expression_filter, c(rep(TRUE,3), sample_filter )]
  }  # order of cts and df kept the same
  cat(paste("Removed genes with less than ", min_rowsum, "reads/fragments across all samples", "\n"))
  cat(paste("Removed samples with less than ", min_colsum, "reads/fragments across all genes", "\n"))
  
  cat(paste("Data dim after filtering:"))
  dim(cts)
}else{
  print("Library size too small: too few genes/samples would be left after filtering, so skipped filtering.")
  print("Please interpret results with caution")
}
# print("Head of filtered data:")
# head(cts)
boxplot(log10(cts+1), las=2, main = "library size after filtering")
```

## COUNT calculation again (after filtering)
```{r}
count <- data.frame(cts)
colnames(count) <- paste(colnames(count),"COUNT", sep = ":")
count_out <- merge(anno, count, by.x=1, by.y=0, all.y=T, sort=F)
head(count_out)
```


## TPM calculation
```{r tpm}
calculateTPM <- function(counts,len) {
  # michael's version
  # https://support.bioconductor.org/p/91218/
  x <- counts/len
  return(t(t(x)*1e6/colSums(x)))
}

if (featureCountsFormat ){
  tpm <- calculateTPM(cts, df$Length)
  tpm <- data.frame(tpm)
  colnames(tpm) <- paste(colnames(tpm),"TPM",  sep = ":")
  tpm_out <- merge(anno, tpm, by.x=1, by.y=0, all.y=T, sort=F)
  # head(tpm_out)
  # tail(tpm_out)
  WriteXLS(x = tpm_out, 
           ExcelFileName = 'TPM.xlsx', row.names = F, SheetNames = 'sheet1', na = 'NA')
  print("saved in TPM.xlsx")
} else {
  cat ("TPM not calculated if COUNT-table is not featureCount format\n")
}
```

## FPKM calculation
```{r fpkm}
calculateFPKM <- function(counts,len) {
  x <- counts
  x <- t(t(x)*1e6/colSums(x))
  return (x/len*1e3)
}

if (featureCountsFormat ){
  fpkm <- calculateFPKM(cts, df$Length)
  fpkm <- data.frame(fpkm)
  colnames(fpkm) <- paste(colnames(fpkm), "FPKM", sep = ":")
  fpkm_out <- merge(anno, fpkm, by.x=1, by.y=0, all.y=T, sort=F)
  # head(fpkm_out)
  # tail(fpkm_out)
  WriteXLS(x = fpkm_out, 
           ExcelFileName = 'FPKM.xlsx', row.names = F, SheetNames = 'sheet1', na = 'NA')
  print("saved in FPKM.xlsx")
  print("Recommend to use TPM, rather than FPKM")
} else {
  cat ("FPKM not calculated if COUNT-table is not featureCount format\n")
}
```

## Design matrix extracted from meta-data
```{r}
meta.df <- readExcel(metaFile)
meta.df <- meta.df[match(colnames(cts), meta.df$SAMPLE_LABEL), ]  # # todo: what if meta has less/more?

contrast.df <- readExcel(contrastFile)

sample <- factor(meta.df$SAMPLE_LABEL)
batch <- factor(meta.df$BATCH)
group <- factor(meta.df$GROUP_LABEL)

coldata <- data.frame(row.names=colnames(cts), 
                      sample,
                      group,
                      batch
                      )
coldata
```

## Model fitting
```{r}
if (length(levels(batch)) > 1){
  dds <- DESeqDataSetFromMatrix(countData = cts, 
                                colData = coldata, 
                                design = ~  0 + group + batch)
}else{
  dds <- DESeqDataSetFromMatrix(countData = cts, 
                                colData = coldata, 
                                design = ~  0 + group)  # converted to alph-order
}
dds
dds <-DESeq(dds)
resultsNames(dds)
#saveRDS(dds, file = 'deseq2.dds.rds')
```

## Save DESeq2 normalized counts
```{r deseq2_norm}
normalized_counts <- counts(dds, normalized=TRUE)
normalized_counts <- data.frame(normalized_counts)
colnames(normalized_counts) <- paste(colnames(normalized_counts),"DESeq2NormalizedCount",  sep = ":")
normalized_counts_out <- merge(anno, normalized_counts, by.x=1, by.y=0, all.y=T, sort=F)
WriteXLS(x = normalized_counts_out, 
         ExcelFileName = 'DESeq2NormalizedCounts.xlsx', row.names = F, SheetNames = 'sheet1', na = 'NA')
print("saved in DESeq2NormalizedCounts.xlsx")
```

## QC Plots

<!-- ## Data transformation -->
<!-- ```{r} -->
<!-- #vsd <- vst(dds, blind=FALSE) -->
<!-- rld <- rlog(dds, blind=FALSE) -->
<!-- counts <- counts(dds, normalized=0) -->
<!-- logCounts <- log10(counts +1 ) -->

<!-- normed <- counts(dds, normalized=1) -->
<!-- logNormed <- log10(normed+1) -->
<!-- ``` -->

### Histogram of Log10(Counts)
```{r histogram}
log1p_count <- log10(counts(dds) + 1)
hist(log1p_count, 
     main = 'Histogram of log10(count + 1)', 
     xlab = "log10(count+1)",
     100) # by default, use non-normalized data by counts function
```

### Dispersion plot
```{r dispersion_plot}
plotDispEsts(dds, main="Dispersion plot")
```


### Sample PCA plot
```{r pca}
plotQC_PCA <- function(dds) {
  vsd <- varianceStabilizingTransformation(dds) # fixed num < num(rowsum>5)
  
  pcaData <- plotPCA(vsd, intgroup = 'group', returnData=TRUE) # labeling fixed
  percentVar <- round(100 * attr(pcaData, 'percentVar'), 1)
  
  if (length(levels(batch)) > 1){
    ggplot(pcaData, aes(PC1, PC2, color = group, shape = batch)) +
    geom_point(size = 3) +
    xlab(paste0("PC1: ", percentVar[1], "% variance")) +
    ylab(paste0("PC2: ", percentVar[2], "% variance")) +
    geom_label_repel(aes(label = sample),
                      box.padding = 0.35,
                      point.padding = 1,
                      segment.color = 'grey50',
                     segment.alpha = 0.5,
                      show.legend = FALSE) + # if TRUE, legend display might not be correct
    theme_classic()
  }else{
    ggplot(pcaData, aes(PC1, PC2, color = group)) +
    geom_point(size = 3) +
    xlab(paste0("PC1: ", percentVar[1], "% variance")) +
    ylab(paste0("PC2: ", percentVar[2], "% variance")) +
    geom_label_repel(aes(label = sample),
                      box.padding = 0.35,
                      point.padding = 1,
                      segment.color = 'grey50',
                     segment.alpha = 0.5,
                      show.legend = FALSE) + # if TRUE, legend display might not be correct
    theme_classic()
  }
}

plotQC_PCA_no_label <- function(dds) {
  vsd <- varianceStabilizingTransformation(dds) # fixed num < num(rowsum>5)
  
  
  pcaData <- plotPCA(vsd, intgroup = 'group', returnData=TRUE) # labeling fixed
  percentVar <- round(100 * attr(pcaData, 'percentVar'), 1)
  
    if (length(levels(batch)) > 1){
        ggplot(pcaData, aes(PC1, PC2, color = group, shape = batch)) +
        geom_point(size = 3) +
        xlab(paste0("PC1: ", percentVar[1], "% variance")) +
        ylab(paste0("PC2: ", percentVar[2], "% variance")) +
        theme_classic()
    }else{
        ggplot(pcaData, aes(PC1, PC2, color = group)) +
        geom_point(size = 3) +
        xlab(paste0("PC1: ", percentVar[1], "% variance")) +
        ylab(paste0("PC2: ", percentVar[2], "% variance")) +
        theme_classic()
    }
  
}

pdf("sample_PCA.labeled.pdf")
plotQC_PCA(dds)
dev.off()

pdf("sample_PCA.pdf")
plotQC_PCA_no_label(dds)
dev.off()

plotQC_PCA(dds)
plotQC_PCA_no_label(dds)
```






### Sample heatmap (Poisson Distance Based)
```{r poisson_heatmap}
colors <- colorRampPalette( rev(brewer.pal(9, "Blues")) )(255)
poisd <- PoissonDistance(t(counts(dds)))
samplePoisDistMatrix <- as.matrix( poisd$dd ) 
rownames(samplePoisDistMatrix) <- coldata$sample
colnames(samplePoisDistMatrix) <- NULL 
colors <- colorRampPalette( rev(brewer.pal(9, "Blues")) )(255)

pheatmap(samplePoisDistMatrix,
         clustering_distance_rows=poisd$dd,
         clustering_distance_cols=poisd$dd,
         col=colors, 
         clustering_method='complete', 
         legend = T, 
         filename = "sample_poisson_distance.pdf")

pheatmap(samplePoisDistMatrix,
         clustering_distance_rows=poisd$dd,
         clustering_distance_cols=poisd$dd,
         col=colors, 
         clustering_method='complete',
         legend = T)
```


```{r, include=F}
### Sample Heatmap (Spearman Corr Based)
# corr <- cor(counts(dds), method="spearman")
# spearman_corrplot <- function(corr){
#   #corr <- round(corr, 2)
#   corrplot(corr, 
#            method="square", type="upper", add=F,  # add-on to previous plot
#            is.corr=T,  # flexible coloring if False
#            order="hclust", hclust.method="complete",
#            tl.pos="lt", diag = T)
#   
#   if (dim(corr)[1]<12){
#     corrplot(corr, 
#              method="number", type="lower", add=T,  # add-on to previous plot
#              is.corr=T,  # flexible coloring if False
#              order="hclust", hclust.method="complete",
#              tl.pos="n", diag = F, cl.pos = "n")
#   }else{
#     corrplot(corr, 
#              method="pie", type="lower", add=T,  # add-on to previous plot
#              is.corr=T,  # flexible coloring if False
#              order="hclust", hclust.method="complete",
#              tl.pos="n", diag = F, cl.pos = "n")
#   }
# }

# pdf(paste("sample_spearman_corr", "pdf", sep="."))
# spearman_corrplot(corr)
# dev.off()
# 
# spearman_corrplot(corr)
```

## DE analysis
```{r, warning=T, de}
gsub("group", "", resultsNames(dds))

for (i in 1:dim(contrast.df)[2]){
  name1 <- contrast.df[1,i]
  name2 <- contrast.df[2,i]
  name1 <- gsub(" ", "", name1)
  name2 <- gsub(" ", "", name2)
  name1 <- gsub(";$", "", name1)
  name2 <- gsub(";$", "", name2)
  name1s <- strsplit(name1, ";") [[1]]
  name2s <- strsplit(name2, ";") [[1]]
  name1 <- gsub(";", ".", name1)
  name2 <- gsub(";", ".", name2)
  
  name <- paste(name1, name2, sep = "_vs_")
  print(paste(">>>", i, name))
  
  # contrast <- c("group", name1, name2)
  
  poss <- match(name1s, gsub("group", "", resultsNames(dds)))
  negs <- match(name2s, gsub("group", "", resultsNames(dds)))
  contrast <- rep(0, length(resultsNames(dds)))
  contrast[poss] <- 1/length(poss)
  contrast[negs] <- -1/length(negs)
  print(data.frame(resNames=gsub("group", "", resultsNames(dds)), 
                   contrast=contrast))
  
  res <- lfcShrink(dds, contrast = contrast, type = 'ashr')
  res2 <- results(dds, contrast = contrast, 
                  independentFilter=indfilter, cooksCutoff=cookscutoff)
  if (featureCountsFormat){
    process_deseq_res(res = res, res2=res2, name = name, anno = anno, norm_exp = tpm)
  } else if (cleanCountFormat | osrCountFormat){
      process_deseq_res(res = res, res2=res2, name = name, anno = anno, norm_exp = normalized_counts)
  } else {
    stop("COUNT table format was wrong")
  }
} 
```



## Log
```{r log}
#save.image(file="../../DESeq2/RSession")
sessionInfo()
```

